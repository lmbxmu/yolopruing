Pruning yolov3 and train on 6 class of COCO2014: person, bicycle, car, motorbike, bus, truck.

## Installation
##### Download pretrained weights
    $ cd weights/
    $ bash download_weights.sh

##### Download COCO
    $ cd data/
    $ bash get_coco_dataset.sh

##### Split COCO dataset

Change items in data/extract.py

- savepath : path to save
- dataset_List : train2014/val2014. You should change items between these and run extract.py two times
- img_dir: same as dataset_List, change between train and val
- anno_dif: same as dataset_List, change between train and val
- dataDir path of COCO dataset

```
$ cd data/
$ python3 extract.py
```

Change items in data/class_refine.pyï¼Œ Also, You should change items between 'train' and 'val', then run class_refine.py two times.

- Dir
- ImageDir

```
$ python3 class_refine.py
```

Change items in data/turn_txt.py. Same as above, You should change items between 'train' and 'val', then run turn_txt.py two times.

- class
- infile
- outfile
- datapath

```
$ python3 turn_txt.py
```

Also, change items in config/coco.data

- train 
- valid

## Inference

Evaluates the model on COCO test.

    $ python3 test.py --weights_path weights/yolov3.weights --pr_cfg 0.4 0.4 0.5 0.5 0.6

## Train
#### Example (COCO)
To train on COCO using a Darknet-53 backend pretrained on ImageNet run: 
```shell
python3 train.py --data_config config/coco.data  --job_dir ./experiments/class_6_pr_1 --pretrained_weights weights/darknet53.conv.74  --pr_cfg 0.4 0.4 0.5 0.5 0.6
```

#### Training log
```
---- [Epoch 7/100, Batch 7300/14658] ----
+------------+--------------+--------------+--------------+
| Metrics    | YOLO Layer 0 | YOLO Layer 1 | YOLO Layer 2 |
+------------+--------------+--------------+--------------+
| grid_size  | 16           | 32           | 64           |
| loss       | 1.554926     | 1.446884     | 1.427585     |
| x          | 0.028157     | 0.044483     | 0.051159     |
| y          | 0.040524     | 0.035687     | 0.046307     |
| w          | 0.078980     | 0.066310     | 0.027984     |
| h          | 0.133414     | 0.094540     | 0.037121     |
| conf       | 1.234448     | 1.165665     | 1.223495     |
| cls        | 0.039402     | 0.040198     | 0.041520     |
| cls_acc    | 44.44%       | 43.59%       | 32.50%       |
| recall50   | 0.361111     | 0.384615     | 0.300000     |
| recall75   | 0.222222     | 0.282051     | 0.300000     |
| precision  | 0.520000     | 0.300000     | 0.070175     |
| conf_obj   | 0.599058     | 0.622685     | 0.651472     |
| conf_noobj | 0.003778     | 0.004039     | 0.004044     |
+------------+--------------+--------------+--------------+
Total Loss 4.429395
---- ETA 0:35:48.821929
```

#### Tensorboard
Track training progress in Tensorboard:
* Initialize training
* Run the command below
* Go to http://localhost:6006/

```
$ tensorboard --logdir='logs' --port=6006
```

#### Other Arguments

```shell
  -h, --help            Show this help message and exit
  --epochs EPOCHS	Num of epochs. default:100
  --batch_size 	Size of each image batch. default:8
  --gradient_accumulations Number of gradient accums before step. default:2
  --model_def		Path to model definition file. default:"config/yolov3.cfg"
  --data_config 	Path to data config file. default:"config/coco.data"
  --pretrained_weights  if specified starts from checkpoint model
  --n_cpu 	number of cpu threads to use during batch generation.default:8 
  --img_size 	size of each image dimension. default:8
  --evaluation_interval interval evaluations on validation set. default:1
  --compute_map 	if True computes mAP every tenth batch. default:False
  --lr 	learning rate. default:0.001
  --job_dir JOB_DIR     The directory where the summaries will be stored.
                        default:./experiments
  --lr_type   lr scheduler. default: step. optional:exp/cos/step/fixed
  --pr_cfg 		prune percentage cofiguration of blocks. eg: 0.3 0.3 0.3 0.3 0.3
  --random_rule		random_rule of preserving filters defaut:random_pretrain. optional:l1_pretrain
```

